{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__Age</th>\n",
       "      <th>num__RestingBP</th>\n",
       "      <th>num__Cholesterol</th>\n",
       "      <th>num__FastingBS</th>\n",
       "      <th>num__MaxHR</th>\n",
       "      <th>num__Oldpeak</th>\n",
       "      <th>cat__Sex_F</th>\n",
       "      <th>cat__Sex_M</th>\n",
       "      <th>cat__ChestPainType_ASY</th>\n",
       "      <th>cat__ChestPainType_ATA</th>\n",
       "      <th>cat__ChestPainType_NAP</th>\n",
       "      <th>cat__ChestPainType_TA</th>\n",
       "      <th>cat__RestingECG_LVH</th>\n",
       "      <th>cat__RestingECG_Normal</th>\n",
       "      <th>cat__RestingECG_ST</th>\n",
       "      <th>cat__ExerciseAngina_N</th>\n",
       "      <th>cat__ExerciseAngina_Y</th>\n",
       "      <th>cat__ST_Slope_Down</th>\n",
       "      <th>cat__ST_Slope_Flat</th>\n",
       "      <th>cat__ST_Slope_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.433140</td>\n",
       "      <td>0.410909</td>\n",
       "      <td>0.825070</td>\n",
       "      <td>-0.551341</td>\n",
       "      <td>1.382928</td>\n",
       "      <td>-0.832432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.478484</td>\n",
       "      <td>1.491752</td>\n",
       "      <td>-0.171961</td>\n",
       "      <td>-0.551341</td>\n",
       "      <td>0.754157</td>\n",
       "      <td>0.105664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.751359</td>\n",
       "      <td>-0.129513</td>\n",
       "      <td>0.770188</td>\n",
       "      <td>-0.551341</td>\n",
       "      <td>-1.525138</td>\n",
       "      <td>-0.832432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.584556</td>\n",
       "      <td>0.302825</td>\n",
       "      <td>0.139040</td>\n",
       "      <td>-0.551341</td>\n",
       "      <td>-1.132156</td>\n",
       "      <td>0.574711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051881</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>-0.034755</td>\n",
       "      <td>-0.551341</td>\n",
       "      <td>-0.581981</td>\n",
       "      <td>-0.832432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__Age  num__RestingBP  num__Cholesterol  num__FastingBS  num__MaxHR  \\\n",
       "0 -1.433140        0.410909          0.825070       -0.551341    1.382928   \n",
       "1 -0.478484        1.491752         -0.171961       -0.551341    0.754157   \n",
       "2 -1.751359       -0.129513          0.770188       -0.551341   -1.525138   \n",
       "3 -0.584556        0.302825          0.139040       -0.551341   -1.132156   \n",
       "4  0.051881        0.951331         -0.034755       -0.551341   -0.581981   \n",
       "\n",
       "   num__Oldpeak  cat__Sex_F  cat__Sex_M  cat__ChestPainType_ASY  \\\n",
       "0     -0.832432         0.0         1.0                     0.0   \n",
       "1      0.105664         1.0         0.0                     0.0   \n",
       "2     -0.832432         0.0         1.0                     0.0   \n",
       "3      0.574711         1.0         0.0                     1.0   \n",
       "4     -0.832432         0.0         1.0                     0.0   \n",
       "\n",
       "   cat__ChestPainType_ATA  cat__ChestPainType_NAP  cat__ChestPainType_TA  \\\n",
       "0                     1.0                     0.0                    0.0   \n",
       "1                     0.0                     1.0                    0.0   \n",
       "2                     1.0                     0.0                    0.0   \n",
       "3                     0.0                     0.0                    0.0   \n",
       "4                     0.0                     1.0                    0.0   \n",
       "\n",
       "   cat__RestingECG_LVH  cat__RestingECG_Normal  cat__RestingECG_ST  \\\n",
       "0                  0.0                     1.0                 0.0   \n",
       "1                  0.0                     1.0                 0.0   \n",
       "2                  0.0                     0.0                 1.0   \n",
       "3                  0.0                     1.0                 0.0   \n",
       "4                  0.0                     1.0                 0.0   \n",
       "\n",
       "   cat__ExerciseAngina_N  cat__ExerciseAngina_Y  cat__ST_Slope_Down  \\\n",
       "0                    1.0                    0.0                 0.0   \n",
       "1                    1.0                    0.0                 0.0   \n",
       "2                    1.0                    0.0                 0.0   \n",
       "3                    0.0                    1.0                 0.0   \n",
       "4                    1.0                    0.0                 0.0   \n",
       "\n",
       "   cat__ST_Slope_Flat  cat__ST_Slope_Up  \n",
       "0                 0.0               1.0  \n",
       "1                 1.0               0.0  \n",
       "2                 0.0               1.0  \n",
       "3                 1.0               0.0  \n",
       "4                 0.0               1.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 20 # 20 features for each batch\n",
    "hidden_size = 100 # can try different sizes\n",
    "num_epochs = 2 # number of times that the full dataset is trained\n",
    "batch_size = 100 # number of training data samples for each iteration\n",
    "learning_rate = 0.001 # magnitude of the change in the weights during update\n",
    "\n",
    "train = pd.read_csv('heart_data.csv')\n",
    "df = pd.DataFrame(data=train)\n",
    "df_train = df.drop(['HeartDisease'], axis=1)\n",
    "# NOTES: X = df.drop(['HeartDisease'], axis=1) # drop label column from feature set\n",
    "# NOTES: y = df['HeartDisease'] # store column label\n",
    "\n",
    "null_rows = df_train.isnull().any(axis=1)\n",
    "df_train.loc[null_rows].head() # no null rows so can skip step to address missing data\n",
    "\n",
    "# one hot encoding (for each sample and its categorical attributes, sets its given category to 1 and others to 0)\n",
    "df_cat = df_train.drop(['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR','Oldpeak'], axis=1) # drop numerical\n",
    "cat_encoder = OneHotEncoder()\n",
    "encoded_cat = cat_encoder.fit_transform(df_cat)\n",
    "\n",
    "# standardize numerical data (convert to scaled range within 0-1)\n",
    "df_num = df_train.select_dtypes(include=[np.number])\n",
    "scaler = StandardScaler()\n",
    "scaled_num = scaler.fit_transform(df_num)\n",
    "\n",
    "# create separate processing pipelines with functions for numerical and categorical data\n",
    "num_pipeline = make_pipeline(StandardScaler())\n",
    "cat_pipeline = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\")) # ignore unknown category values (if applicable)\n",
    "num_cols = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR','Oldpeak']\n",
    "cat_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "\n",
    "preprocessing = ColumnTransformer([(\"num\", num_pipeline, num_cols), (\"cat\", cat_pipeline, cat_cols)])\n",
    "processed_data = preprocessing.fit_transform(df_train)\n",
    "processed_df = pd.DataFrame(processed_data, columns=preprocessing.get_feature_names_out(), index=df_train.index)\n",
    "\n",
    "processed_df_full = processed_df.copy()\n",
    "processed_df_full.insert(0, \"HeartDisease\", df[\"HeartDisease\"].to_numpy(), False) # full data to use in dataset class (as csv)\n",
    "processed_csv = processed_df_full.to_csv('processed_heart_data.csv', index=False)\n",
    "\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        xy = np.loadtxt('processed_heart_data.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
    "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module): # custom neural net derived from pytorch\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) # layer 1 uses linear function on neurons using input\n",
    "        self.relu = nn.ReLU() # activation function, decides how the neurons in next layer activate based on factoring in weights and activations of previous neurons (converts activation values to range 0 to +)\n",
    "        self.l2 = nn.Linear(hidden_size, 1) # layer 2 uses linear function on neurons to return output (1 class since outcome of heart disease)\n",
    "    \n",
    "    def forward(self, x): # trains by going forward through neural net to calculate initial output values\n",
    "        out = self.l1(x) # apply layer 1 on input neurons\n",
    "        out = self.relu(out) \n",
    "        out = self.l2(out) # apply layer 2 on layer 1 output neurons to get class values\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4331,  0.4109,  0.8251, -0.5513,  1.3829, -0.8324,  0.0000,  1.0000,\n",
      "         0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,\n",
      "         0.0000,  0.0000,  0.0000,  1.0000]) tensor([0.])\n",
      "torch.Size([100, 20]) torch.Size([100, 1])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "dataset = HeartDataset()\n",
    "first_data = dataset[0] # get first sample and get separate features and labels\n",
    "features, labels = first_data\n",
    "print(features, labels)\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader) # to iterate through samples\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape) \n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 2, step 1 / 10, loss = 0.6865\n",
      "epoch 1 / 2, step 2 / 10, loss = 0.6620\n",
      "epoch 1 / 2, step 3 / 10, loss = 0.6758\n",
      "epoch 1 / 2, step 4 / 10, loss = 0.6670\n",
      "epoch 1 / 2, step 5 / 10, loss = 0.6547\n",
      "epoch 1 / 2, step 6 / 10, loss = 0.6426\n",
      "epoch 1 / 2, step 7 / 10, loss = 0.6375\n",
      "epoch 1 / 2, step 8 / 10, loss = 0.6236\n",
      "epoch 1 / 2, step 9 / 10, loss = 0.6341\n",
      "epoch 1 / 2, step 10 / 10, loss = 0.6077\n",
      "epoch 2 / 2, step 1 / 10, loss = 0.6227\n",
      "epoch 2 / 2, step 2 / 10, loss = 0.6020\n",
      "epoch 2 / 2, step 3 / 10, loss = 0.6112\n",
      "epoch 2 / 2, step 4 / 10, loss = 0.6039\n",
      "epoch 2 / 2, step 5 / 10, loss = 0.5759\n",
      "epoch 2 / 2, step 6 / 10, loss = 0.5875\n",
      "epoch 2 / 2, step 7 / 10, loss = 0.5879\n",
      "epoch 2 / 2, step 8 / 10, loss = 0.5665\n",
      "epoch 2 / 2, step 9 / 10, loss = 0.5627\n",
      "epoch 2 / 2, step 10 / 10, loss = 0.5540\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size)\n",
    "# factors in the actual class Y  and log(predicted class probability Y-hat) similar to cross entropy loss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # optimizer to update weights using gradients calculated from loss\n",
    "\n",
    "# train samples\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features = features.reshape(-1, input_size).to(device) # reshape images array from 100,20 to 20 due to input size 918\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass through neural network to get initial output class values\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backpropagation to calculate gradients and then update weights \n",
    "        # find gradient d Loss / dw from output layer to input layer, via chain rule applied to equation applying weights to activations and to activation function applied on that result\n",
    "        optimizer.zero_grad() # avoids adding gradients from previous sample to current\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 1 == 0: # print for every 100 samples\n",
    "            print(f'epoch {epoch + 1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8376906318082789\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for entries, labels in test_dataloader:\n",
    "        entries = entries.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(entries)\n",
    "\n",
    "        # Apply sigmoid activation to convert logits to probabilities\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "\n",
    "        # Convert probabilities to binary predictions (0 or 1)\n",
    "        predictions = (probabilities > 0.5).float()\n",
    "\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
